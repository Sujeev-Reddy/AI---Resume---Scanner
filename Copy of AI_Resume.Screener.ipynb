{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1B2C8QzbYt08zLtB7IflDf4KEMdxMmv7O","timestamp":1760254953808}],"authorship_tag":"ABX9TyPkFOIEpxlohpFi+ewQGzm1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Install Libraries"],"metadata":{"id":"R7YsqhGOV-El"}},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"hA79BmglVnJ2","executionInfo":{"status":"ok","timestamp":1760753119265,"user_tz":-330,"elapsed":5701,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"b92a4fde-4c6a-4e76-f5b7-b7de9efdb236"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n","Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.5)\n","Requirement already satisfied: docx2txt in /usr/local/lib/python3.12/dist-packages (0.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.57.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (2.8.0+cu126)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.16.2)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (0.35.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.19.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.8.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.3)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.10)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","\n","Usage:   \n","  pip3 <command> [options]\n","\n","no such option: -m\n"]}],"source":["!pip install streamlit sentence_transformers pymupdf docx2txt pandas spacy matplotlib\n","!pip -m spacy download en_core_web_sm"]},{"cell_type":"code","source":["import fitz, docx2txt, spacy, pandas as pd\n","from sentence_transformers import SentenceTransformer\n","print(\"All libraries installed correctly\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wtdm4tZUWkBv","executionInfo":{"status":"ok","timestamp":1760753119277,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"d89fab43-09b2-4f32-ed19-ef80660aabd3"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["All libraries installed correctly\n"]}]},{"cell_type":"code","source":["import fitz\n","import docx2txt\n","import re\n","from google.colab import files"],"metadata":{"id":"GlMk04xltvW0","executionInfo":{"status":"ok","timestamp":1760753119314,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ShOa8cscdvTn","executionInfo":{"status":"ok","timestamp":1760753121073,"user_tz":-330,"elapsed":1757,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"05a2ef93-81b1-471e-830e-39beecab6165"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mfZZMY3xf1ay","executionInfo":{"status":"ok","timestamp":1760753121199,"user_tz":-330,"elapsed":31,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"cb0f67fb-9506-4c44-8940-d0e4bad67463"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":[" 1627984789883.gdoc\n"," 1627984789883.pdf\n","'20-20 & 50-50 Series (Reg Students)'\n","'Colab Notebooks'\n","'Copy of Data Journal: Journal Entry Templates.gdoc'\n"," DSC_0170.JPG\n","'Getting started.pdf'\n","'HD472877_EquityP&L_01-Feb-2021_07-Feb-2021.xls'\n","'My resume- India - Google Docs-converted.gdoc'\n","'new doc 2024-08-04 17.46.34.pdf'\n","'new doc 2024-08-04 17.47.08 (1).pdf'\n","'new doc 2024-08-04 17.47.08.pdf'\n","'new doc 2024-08-04 17.47.38.pdf'\n","'new doc 2024-08-04 17.47.59.pdf'\n","'new doc 2024-08-04 17.48.19.pdf'\n","'resume (1).gdoc'\n"," resume.gdoc\n"," resume_juanjosecarin.pdf\n"," resume.pdf\n"," Statistics\n","'Untitled spreadsheet.gsheet'\n"," XXXXXXXXXXX1263-28-11-2022to27-02-2023.pdf\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29665b33","executionInfo":{"status":"ok","timestamp":1760753121304,"user_tz":-330,"elapsed":103,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"137bc233-9777-4d89-ee07-e0afccf5301d"},"source":["!ls /content/drive/MyDrive/'Colab Notebooks'/"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":[" AI_Resume.Screener.ipynb\t     resume_juanjosecarin.pdf\n"," App.py\t\t\t\t    'Text Generation.ipynb'\n","'Copy of AI_Resume.Screener.ipynb'   the_first.ipynb\n","'Copy of App.py'\t\t     Untitled0.ipynb\n","'Kallu Sujeev Reddy.pdf'\n"]}]},{"cell_type":"markdown","source":["Extraction Function"],"metadata":{"id":"vnz4xWtTyRG0"}},{"cell_type":"code","source":["def extract_text(file_path):\n","  text = \"\" # Initialize text here\n","\n","  if file_path.endswith(\".pdf\"):\n","    with fitz.open(file_path) as pdf :\n","      for page in pdf:\n","        text += page.get_text(\"text\")\n","\n","  elif file_path.endswith(\".docx\"):\n","    text = docx2txt.process(file_path)\n","\n","  else :\n","    print(\"File not supported !!\")\n","\n","  # Basic Cleaning\n","  text = re.sub(r'\\s+', ' ',text).strip()\n","  return text"],"metadata":{"id":"zXA_MIQ_yUeh","executionInfo":{"status":"ok","timestamp":1760753121361,"user_tz":-330,"elapsed":29,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["file_path = \"/content/drive/MyDrive/Colab Notebooks/resume_juanjosecarin.pdf\"\n","text = extract_text(file_path)\n","print(text[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BmtyLc9Jgpqq","executionInfo":{"status":"ok","timestamp":1760753121403,"user_tz":-330,"elapsed":44,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"5a4fe144-57f8-489e-e32f-ce037ac6add1"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["1 of 2 Juan Jose Carin Data Scientist Mountain View, CA 94041 650-336-4590 | juanjose.carin@gmail.com linkedin.com/in/juanjosecarin | juanjocarin.github.io Professional Profile Passionate about data analysis and experiments, mainly focused on user behavior, experience, and engagement, with a solid background in data science and statistics, and extensive experience using data insights to drive business growth. Education 2016 University of California, Berkeley Master of Information and Data Science GPA: 3.93 Relevant courses: • Machine Learning • Machine Learning at Scale • Storing and Retrieving Data • Field Experiments • Applied Regression and Time Series Analysis • Exploring and Analyzing Data • Data Visualization and Communication • Research Design and Applications for Data Analysis 2014 Universidad Politécnica de Madrid M.S. in Statistical and Computational Information Processing GPA: 3.69 Relevant courses: • Data Mining • Multivariate Analysis • Time Series • Neural Networks and St\n"]}]},{"cell_type":"markdown","source":["Text Extraction"],"metadata":{"id":"P6vu-SOgWjwL"}},{"cell_type":"code","source":["import os\n","folder_path = \"/content/drive/MyDrive/Colab Notebooks/\" # Corrected to the folder path\n","\n","for file_name in os.listdir(folder_path):\n","  if file_name.endswith(\".pdf\") or file_name.endswith(\"docx\"):\n","    file_path = os.path.join(folder_path, file_name) # Corrected filename to file_name\n","    extracted = extract_text(file_path)\n","    print(f\"File : {file_name}\")\n","    print(f\"Extracted text sample :/n{extracted[:500]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AbJiIigYQpD","executionInfo":{"status":"ok","timestamp":1760753124457,"user_tz":-330,"elapsed":3054,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"1dc91933-74f2-4aeb-d364-03847543608c"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["File : resume_juanjosecarin.pdf\n","Extracted text sample :/n1 of 2 Juan Jose Carin Data Scientist Mountain View, CA 94041 650-336-4590 | juanjose.carin@gmail.com linkedin.com/in/juanjosecarin | juanjocarin.github.io Professional Profile Passionate about data analysis and experiments, mainly focused on user behavior, experience, and engagement, with a solid background in data science and statistics, and extensive experience using data insights to drive business growth. Education 2016 University of California, Berkeley Master of Information and Data Scienc\n","File : Kallu Sujeev Reddy.pdf\n","Extracted text sample :/nKALLU SUJEEV REDDY Hyderabad, IN | sujeevreddy93@gmail.com | 9100780854 | https://www.linkedin.com/in/sujeevreddykallu/ PROFESSIONAL SUMMARY Innovative Data Scientist with experience building LLM-driven workflows and autonomous agents for Finance and HR operations. Skilled in designing NLP pipelines, anomaly detection systems, and AI- powered chatbots for document summarization and retrieval. Combines advanced AI capabilities with a strong foundation in BI tools to drive smarter decision-making \n"]}]},{"cell_type":"markdown","source":["Extract Structured Data"],"metadata":{"id":"Fhp_lK3zjLBx"}},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"id":"SH2HHtpNnnlk","executionInfo":{"status":"ok","timestamp":1760753126217,"user_tz":-330,"elapsed":1726,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["def extract_structured_data(text):\n","    data = {\n","        \"Name\": None,\n","        \"Email\": None,\n","        \"Phone\": None,\n","        \"Education\": [],\n","        \"Experience\": [],\n","        \"Skills\": []\n","    }\n","\n","## ----- Extract EMAIL -----\n","\n","    email_match = re.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n","    if email_match:\n","        data[\"Email\"] = email_match.group(0)\n","\n","## ----- Extract PHONE ----\n","\n","    phone_match = re.search(r'(\\+?\\d{1,3}[\\s-]?)?\\(?\\d{3,5}\\)?[\\s.-]?\\d{3,5}[\\s.-]?\\d{3,5}', text)\n","    if phone_match:\n","        data[\"Phone\"] = phone_match.group(0)\n","\n","## ---- Extract SKILLS ----\n","\n","    skill_keywords = [\n","        \"python\", \"excel\", \"sql\", \"machine learning\", \"deep learning\", \"communication\", \"power bi\",\n","        \"tableau\", \"data analysis\", \"r\", \"java\", \"c++\", \"tensorflow\", \"pytorch\", \"nlp\"\n","    ]\n","    found_skills = [skill for skill in skill_keywords if skill.lower() in text.lower()]\n","    data[\"Skills\"] = found_skills\n","\n","## ---- Extract NAME -----\n","\n","  ## to extract name from top section of resume\n","\n","    top_section = \"\\n\".join(text.split(\"\\n\")[:10]).strip()   # takes only first 10 lines\n","\n"," ## to remove lines that contain emails and phone numbers\n","\n","    top_section = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '', top_section)\n","    top_section = re.sub(r'(\\+?\\d{1,3}[\\s-]?)?\\(?\\d{2,4}\\)?[\\s.-]?\\d{3,5}[\\s.-]?\\d{3,5}', '', top_section)\n","\n"," ## Run spaCY NER\n","\n","    doc = nlp(top_section)\n","\n","## Lookin for PERSON entities\n","\n","    name_candidates = [ent.text.strip() for ent in doc.ents if ent.label_ == \"PERSON\"] # Corrected ent.label to ent.label_\n","\n","    if name_candidates:\n","      data[\"Name\"] = name_candidates[0] # Assign the found name to data[\"Name\"]\n","\n","    # \"\"\"for line in top_section.split(\"\\n\"):\n","    #    line = line.strip()\n","    #    if line and re.match(r'^[A-Za-z\\s\\.-]{3,}$', line) and len(line.split()) <= 4:\n","    #        return line \"\"\" # Commented out and indented the block\n","\n","\n","## ----- Extract EDUCATION -----\n","\n","  ## Extracting Education based on \"Education heading\". Captures everything until next major heading\n","\n","    text_lower = text.lower()\n","\n","    next_sections = ['experience', 'project', 'projects', 'skill', 'skills', 'award', 'awards', 'certification', 'certifications']\n","\n","  ## Finding the start of Education section\n","\n","    edu_match = re.search(r'\\beducation\\b', text_lower)\n","    if not edu_match:\n","     return data # Return data if no education section found\n","\n","    edu_start = edu_match.start() # Corrected variable name\n","\n","\n","  ## Initialising the end of Education section\n","\n","    edu_end = len(text)\n","\n","  ## Finding the closest next section after Education\n","\n","    for sec in next_sections:\n","        sec_match = re.search(r'\\b' + re.escape(sec) + r'\\b', text_lower[edu_start + 1:])\n","        if sec_match:\n","            potential_end = edu_start + 1 + sec_match.start()\n","            if potential_end < edu_end:\n","                edu_end = potential_end\n","\n","  ## Extracting and cleaning the section\n","    education_text = text[edu_start:edu_end].strip()\n","\n","    education_text = re.sub(r'\\n{2,}', '\\n', education_text)\n","    data[\"Education\"] = education_text # Assign the extracted education text to data[\"Education\"]\n","\n","\n","## ----- Extract EXPERIENCE -----\n","\n","    text_lower = text.lower()\n","\n","    # Define possible next section headers\n","    next_sections = ['education', 'project', 'projects', 'skill', 'skills', 'award', 'awards', 'certification', 'certifications']\n","\n","    # Find where the 'experience' section starts\n","    exp_match = re.search(r'\\bexperience\\b', text_lower)\n","    if not exp_match:\n","        return data  # Return data if no Experience section found\n","\n","    exp_start = exp_match.start()\n","\n","    # Initialize end of Experience section as end of text\n","    exp_end = len(text)\n","\n","    # Find the closest next section header after 'experience'\n","    for sec in next_sections:\n","        sec_match = re.search(r'\\b' + re.escape(sec) + r'\\b', text_lower[exp_start + 1:])\n","        if sec_match:\n","            potential_end = exp_start + 1 + sec_match.start()\n","            if potential_end < exp_end:\n","                exp_end = potential_end\n","\n","    # Extract and clean the Experience section\n","    experience_text = text[exp_start:exp_end].strip()\n","    experience_text = re.sub(r'\\n{2,}', '\\n', experience_text)\n","    data[\"Experience\"] = experience_text # Assign the extracted experience text to data[\"Experience\"]\n","\n","\n","    return data"],"metadata":{"id":"X5MdhG3NIFZF","executionInfo":{"status":"ok","timestamp":1760753126221,"user_tz":-330,"elapsed":1,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["Resume Text Extraction Check"],"metadata":{"id":"BPaytNfZ1zom"}},{"cell_type":"code","source":["import os\n","\n","folder_path = \"/content/drive/MyDrive/Colab Notebooks/\"\n","\n","# Loop through all files in folder\n","for filename in os.listdir(folder_path):\n","    if filename.endswith(\".pdf\") or filename.endswith(\".docx\"):\n","        file_path = os.path.join(folder_path, filename)\n","        text = extract_text(file_path)\n","        info = extract_structured_data(text) # Pass the extracted text here\n","\n","        print(f\"Resume: {filename}\")\n","        for k, v in info.items():\n","            print(f\"{k}: {v}\\n\")\n","        print(\"=\"*80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jlturi6cXONY","executionInfo":{"status":"ok","timestamp":1760753126824,"user_tz":-330,"elapsed":601,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"4808d3f0-164f-40bf-f0c8-6f56b1aa4403"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Resume: resume_juanjosecarin.pdf\n","Name: Hive\n","\n","Email: juanjose.carin@gmail.com\n","\n","Phone: 94041 650-336\n","\n","Education: Education 2016 University of California, Berkeley Master of Information and Data Science GPA: 3.93 Relevant courses: • Machine Learning • Machine Learning at Scale • Storing and Retrieving Data • Field Experiments • Applied Regression and Time Series Analysis • Exploring and Analyzing Data • Data Visualization and Communication • Research Design and Applications for Data Analysis 2014 Universidad Politécnica de Madrid M.S. in Statistical and Computational Information Processing GPA: 3.69 Relevant courses: • Data Mining • Multivariate Analysis • Time Series • Neural Networks and Statistical Learning • Regression and Prediction Methods • Optimization Techniques • Monte Carlo Techniques • Numerical Methods in Finance • Stochastic Models in Finance • Bayesian Networks 2005 Universidad Politécnica de Madrid M.S. in Telecommunication Engineering GPA: 3.03 Focus Area: Radio communication systems (radar and mobile). Fellowship: First year at University, due to Honors obtained last year at high school.\n","\n","Experience: experience, and engagement, with a solid background in data science and statistics, and extensive experience using data insights to drive business growth.\n","\n","Skills: ['python', 'sql', 'machine learning', 'communication', 'tableau', 'data analysis', 'r', 'tensorflow']\n","\n","================================================================================\n","Resume: Kallu Sujeev Reddy.pdf\n","Name: Wissen Infotech\n","\n","Email: sujeevreddy93@gmail.com\n","\n","Phone: 9100780854\n","\n","Education: EDUCATION  Murray State University (2015 – 2016) --- Master of Science (Engineering Technology Management)  Osmania University (2011 – 2015) --- Bachelor of Science (Civil Engineering)\n","\n","Experience: experience building LLM-driven workflows and autonomous agents for Finance and HR operations. Skilled in designing NLP pipelines, anomaly detection systems, and AI- powered chatbots for document summarization and retrieval. Combines advanced AI capabilities with a strong foundation in BI tools to drive smarter decision-making and automation. EXPERIENCE Data Scientist Wissen Infotech | Hyderabad April 2023 – Present  Currently architecting Agentic AI workflows for the Finance division, aimed at automating manual expense review processes through LLM-driven task chaining, anomaly detection, and policy compliance checks.  Building autonomous agents with capabilities to interpret structured and unstructured data, cross-reference company policies, and generate audit-friendly reports, cutting repetitive effort for Finance analysts.  Prototyped intelligent systems for flagging suspicious reimbursements, enhancing operational efficiency and paving the way for low-touch financial audits  Spearheaded the development of an enterprise-grade AI chatbot for internal document retrieval and summarization, enabling HR and Tech teams to access critical organizational knowledge through natural language queries, reducing manual document search efforts by 40%.  Designed and deployed NLP pipelines combining text embeddings, vector search, and summarization models, significantly boosting document relevance and response accuracy.  Ensured seamless integration of the chatbot into corporate infrastructure with attention to data governance, user privacy, and multi-department usability. Data Analyst Wissen Infotech | Hyderabad June 2021 – March 2023  Collaborated with cross-functional teams to design predictive models for operational insights, leveraging regression and classification techniques to forecast trends and detect anomalies in business data.  Applied machine learning algorithms to structured datasets for churn prediction and customer segmentation, improving targeting strategies and retention efforts.  Engineered feature pipelines using Python and SQL to prepare data for ML models, including handling missing values, encoding categorical variables, and scaling numerical features.  Conducted exploratory data analysis (EDA) to uncover patterns and inform model selection, using statistical techniques and visualizations to guide stakeholders.  Integrated ML outputs into Power BI dashboards, enabling dynamic decision-making through model-driven KPIs and scenario simulations.  Automated data preprocessing workflows with Python scripts and Power Query, reducing manual effort and ensuring consistency across analytics\n","\n","Skills: ['python', 'sql', 'machine learning', 'deep learning', 'power bi', 'data analysis', 'r', 'tensorflow', 'pytorch', 'nlp']\n","\n","================================================================================\n"]}]},{"cell_type":"markdown","source":["Matching Resume to Job Description"],"metadata":{"id":"ntrtxPif_IF5"}},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer, util\n","import numpy as np"],"metadata":{"id":"LKKbOCO6_RxY","executionInfo":{"status":"ok","timestamp":1760753126828,"user_tz":-330,"elapsed":2,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["## Loading a Pretrained Embedding Model\n","\n","model = SentenceTransformer('all-MiniLM-L6-v2')"],"metadata":{"collapsed":true,"id":"-fTvVs-gACt3","executionInfo":{"status":"ok","timestamp":1760753128027,"user_tz":-330,"elapsed":1197,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["## Input manual job description\n","\n","job_description = \"\"\"\n","We are looking for a Data Analyst skilled in Python, SQL, Excel, and Power BI.\n","The ideal candidate should have experience with data visualization and basic machine learning.\n","\"\"\""],"metadata":{"id":"f-gxAQAWAiNg","executionInfo":{"status":"ok","timestamp":1760753128031,"user_tz":-330,"elapsed":2,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["## Computing Similarity b/w JD and Resume\n","\n","def compute_similarity(resume_text, job_description):\n","    # Encode both texts into embeddings\n","    embeddings = model.encode([resume_text, job_description], convert_to_tensor=True)\n","    # Compute cosine similarity\n","    score = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n","    return float(score)"],"metadata":{"id":"1AuU2sp2CVre","executionInfo":{"status":"ok","timestamp":1760753128042,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["## Apply to all uploaded resumes\n","\n","resume_folder = \"/content/drive/MyDrive/Colab Notebooks/\"\n","\n","results = []\n","\n","# Loop through all PDF files in the folder\n","for filename in os.listdir(resume_folder):\n","    if filename.lower().endswith(\".pdf\"):   # only process PDFs\n","        filepath = os.path.join(resume_folder, filename)\n","\n","        # Extract text from the resume\n","        text = extract_text(filepath)\n","\n","        # Compute similarity with job description\n","        similarity_score = compute_similarity(text, job_description)\n","\n","        # Append result\n","        results.append((filename, similarity_score))\n","\n","# Sort by similarity score (descending order)\n","results = sorted(results, key=lambda x: x[1], reverse=True)\n","\n","# Display the results\n","for name, score in results:\n","    print(f\"{name} --> Match Score: {score:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FULzZ2UMDRqn","executionInfo":{"status":"ok","timestamp":1760753129033,"user_tz":-330,"elapsed":989,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"8e6c3ac1-7593-41c8-dd35-13fb6d82a730"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["resume_juanjosecarin.pdf --> Match Score: 0.4401\n","Kallu Sujeev Reddy.pdf --> Match Score: 0.3438\n"]}]},{"cell_type":"markdown","source":["Deploying to Streamlit"],"metadata":{"id":"myFG76IRFY1c"}},{"cell_type":"code","source":["!pip install streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"gmRvO9k3FYWI","executionInfo":{"status":"ok","timestamp":1760753480086,"user_tz":-330,"elapsed":4690,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"237f54bd-7df7-4bdf-a5ac-49689b05016b"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.8.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import fitz\n","import docx2txt\n","import re\n","import pandas as pd\n","from sentence_transformers import SentenceTransformer, util\n","\n","# Load model\n","model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","# --- Helper Functions ---\n","def extract_text(file_path):\n","    text = \"\"\n","    if file_path.name.endswith(\".pdf\"):\n","        with fitz.open(stream=file_path.read(), filetype=\"pdf\") as pdf:\n","            for page in pdf:\n","                text += page.get_text(\"text\")\n","    elif file_path.name.endswith(\".docx\"):\n","        text = docx2txt.process(file_path)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","def compute_similarity(resume_text, job_description):\n","    embeddings = model.encode([resume_text, job_description], convert_to_tensor=True)\n","    score = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n","    return float(score)\n","\n","# --- Streamlit App ---\n","st.title(\"AI Resume Screener (Beginner Project)\")\n","st.write(\"Upload resumes and a job description to rank candidates by relevance!\")\n","\n","# Job Description input\n","job_description = st.text_area(\"Paste Job Description Here:\")\n","\n","# Resume uploads\n","uploaded_files = st.file_uploader(\"Upload Resumes (PDF or DOCX)\", type=[\"pdf\", \"docx\"], accept_multiple_files=True)\n","\n","if st.button(\"Analyze Resumes\"):\n","    if not job_description or not uploaded_files:\n","        st.warning(\"Please upload resumes and provide a job description.\")\n","    else:\n","        results = []\n","        for resume in uploaded_files:\n","            text = extract_text(resume)\n","            score = compute_similarity(text, job_description)\n","            results.append({\"Filename\": resume.name, \"Match Score\": round(score, 3)})\n","\n","        df = pd.DataFrame(results).sort_values(by=\"Match Score\", ascending=False)\n","        st.success(\"Analysis Complete! See below:\")\n","        st.dataframe(df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ngSIYSgtFhzU","executionInfo":{"status":"ok","timestamp":1760753664355,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sujeev Reddy","userId":"13635775426595767765"}},"outputId":"58afc04a-277c-455e-edaa-e7bb5bd11fc2"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]}]}